{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b897dd5d-bb0f-4f08-845e-a3d7a9e07ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f43ae4515d84f98887a24657ad770ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c5cc4d666a4d21a7b61a0bc85432f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9429f856814cad8342ac6d5b7b9438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21016 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "import torch\n",
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration, Trainer, TrainingArguments\n",
    "\n",
    "# Load processed dataset (from benchmark.json)\n",
    "with open(\"benchmark.json\", \"r\") as f:\n",
    "    benchmark_data = json.load(f)\n",
    "\n",
    "# Access medqa dataset\n",
    "medqa_data = benchmark_data['medqa']\n",
    "\n",
    "# Initialize RAG tokenizer and model\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-sequence-nq\")\n",
    "retriever = RagRetriever.from_pretrained(\"facebook/rag-sequence-nq\", index_name=\"exact\", passages_path=\"path_to_index\")  \n",
    "model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-sequence-nq\").to(\"cuda\")  # Move model to GPU\n",
    "\n",
    "# Tokenize question and move tensors to GPU\n",
    "question = \"What is the medical term for...\"\n",
    "inputs = tokenizer(question, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate an answer\n",
    "generated = model.generate(inputs['input_ids'])  # Model is already on GPU\n",
    "answer = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "print(\"Generated Answer:\", answer)\n",
    "\n",
    "# Training setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True  # Mixed precision training\n",
    ")\n",
    "\n",
    "# Wrap medqa_data in Dataset format if needed\n",
    "# Assuming medqa_data is structured like a Dataset\n",
    "trainer = Trainer(\n",
    "    model=model,  # Model is already on GPU\n",
    "    args=training_args,\n",
    "    train_dataset=medqa_data,  # Ensure this dataset is compatible\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save generated answers\n",
    "results = {\"question\": question, \"generated_answer\": answer}\n",
    "with open('generated_answers_gpu.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc112fa-a757-432c-aa78-3410d0985b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3578afd4-b928-49be-b7cd-d1c216882e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766c1dfe-9449-4825-a473-6e2ea2c4e261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e857e7b-cdc1-4c3c-82cc-ccbb276e9fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3eb15-7b2f-4933-874d-f118457e4d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7190504-ef42-41af-aaa8-b38d89bd3927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd854db-60e8-4bec-8db5-69971dbaedcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c634c33-4656-40a5-b028-bdab2e60fa7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b2b99-757a-4317-a4fc-ffe7a9edc466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e20a5-513a-430e-9387-dfbc364a49ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62491b74-00b2-4967-84d2-1d0a9c2311f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5805bc6-2942-4ac2-b34c-8b4bba02e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "# Load processed dataset (you can load the benchmark generated earlier)\n",
    "with open(\"benchmark.json\", \"r\") as f:\n",
    "    benchmark_data = json.load(f)\n",
    "\n",
    "# Example: Access medqa dataset\n",
    "medqa_data = benchmark_data['medqa']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65eee65-3082-4aa4-8dce-777b0d66804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d68508aebd471c9c54ebdea23fc690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35e0e0a76b24c52b1bcbdc99f43ac6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35a453655d8421a8a22fbe0b83b4020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21016 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-sequence-nq\")\n",
    "retriever = RagRetriever.from_pretrained(\"facebook/rag-sequence-nq\", index_name=\"exact\", passages_path=\"path_to_index\")  \n",
    "model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-sequence-nq\").to(\"cuda\")  # Load model to GPU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c23b43a-a998-4e27-ac50-750b1f4ba4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"What is the medical term for...\", return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Example: Generate an answer\n",
    "generated = model.generate(inputs['input_ids'])  # Model is already on GPU\n",
    "answer = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f105a-da5e-499f-ac41-7fc3de8c8fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,  # Enable mixed precision training for faster training on GPU\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,  # Model is already on GPU\n",
    "    args=training_args,\n",
    "    train_dataset=medqa_data,  # Ensure this dataset is loaded and prepared\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f77e7-37b3-4598-9c56-641bf0c5b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save generated answers\n",
    "results = {\"question\": question, \"generated_answer\": answer}\n",
    "with open('generated_answers_gpu.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4074d2-915d-4ec6-8d56-3756bf156a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
